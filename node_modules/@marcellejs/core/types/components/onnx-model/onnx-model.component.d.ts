import type { RegularArray } from '@tensorflow/tfjs-core/dist/types';
import ort from 'onnxruntime-web';
import { ClassifierResults, Instance, Model, Stream } from '../../core';
export interface InputTypes {
    image: ImageData;
    generic: RegularArray<number>;
}
export interface OutputTypes {
    classification: string;
    generic: number[];
}
export interface PredictionTypes {
    classification: ClassifierResults;
    generic: Record<string, Array<number>>;
}
export interface ONNXModelOptions<T, U> {
    inputType: T;
    taskType: U;
    inputShape: number[];
}
export interface ONNXInstance<InputType, OutputType> extends Instance {
    x: InputType;
    y: OutputType;
}
export declare class OnnxModel<InputType extends keyof InputTypes, TaskType extends keyof OutputTypes> extends Model<ONNXInstance<InputTypes[InputType], OutputTypes[TaskType]>, PredictionTypes[TaskType]> {
    #private;
    title: string;
    parameters: {};
    serviceName: string;
    $loading: Stream<boolean>;
    $ready: Stream<boolean>;
    inputType: InputType;
    taskType: TaskType;
    inputShape: number[];
    modelName: string;
    labels: string[];
    lockLoading: Promise<void>;
    constructor({ inputType, taskType, inputShape }: ONNXModelOptions<InputType, TaskType>);
    train(): never;
    predict(input: InputTypes[InputType]): Promise<PredictionTypes[TaskType]>;
    loadFromUrl(url: string): Promise<void>;
    loadFromFile(file: File): Promise<void>;
    loadModel(source: string | ArrayBuffer, modelName: string): Promise<void>;
    preprocess(input: InputTypes[InputType]): ort.Tensor;
    preprocessImage(img: InputTypes['image']): ort.Tensor;
    postprocess(outputs: ort.InferenceSession.OnnxValueMapType): Promise<PredictionTypes[TaskType]>;
    warmup(): Promise<void>;
    mount(target?: HTMLElement): void;
    save(): never;
    load(): never;
    download(): never;
    upload(): never;
}
